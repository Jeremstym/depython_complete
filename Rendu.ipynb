{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rturquier/depythons/blob/main/Rendu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyDgk7w54dfJ"
   },
   "source": [
    "#### Projet informatique - Python pour le data scientist\n",
    "##### Jérémie Stym-Popper, Luca Teodorescu, Rémi Turquier\n",
    "# _La République en Marche_ est-elle de gauche ou de droite ?\n",
    "\n",
    "[Titre provisoire]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u6CCHVOX7XDx"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6wrFWawkgh1"
   },
   "source": [
    "## Récupération des données\n",
    "Les données ont été récupérées par l'intermédiaire de [l'API](https://github.com/regardscitoyens/nosdeputes.fr/blob/master/doc/api.md) mise à disposition par l'association Regards citoyens.\n",
    "\n",
    "Nous avons d'abord utilisé un module nommé depute_api, que nous avons ensuite complété avec trois fonctions :\n",
    "Les fonctions *interventions* et *interventions2* permettent d'entrer le nom d'un député pour obtenir une liste d'interventions (sous forme de liste de str).\n",
    "La fonction ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OW5P37oZPCVR"
   },
   "outputs": [],
   "source": [
    "# ----- Codage de l'API --------------------------------------------------\n",
    "from operator import itemgetter\n",
    "import requests\n",
    "import warnings\n",
    "import re\n",
    "import bs4\n",
    "import unidecode\n",
    "from urllib import request\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    from fuzzywuzzy.process import extractBests\n",
    "\n",
    "\n",
    "__all__ = ['CPCApi']\n",
    "\n",
    "\n",
    "def memoize(f):\n",
    "    cache = {}\n",
    "\n",
    "    def aux(*args, **kargs):\n",
    "        k = (args, tuple(sorted(kargs.items())))\n",
    "        if k not in cache:\n",
    "            cache[k] = f(*args, **kargs)\n",
    "        return cache[k]\n",
    "    return aux\n",
    "\n",
    "\n",
    "class CPCApi(object):\n",
    "    format = 'json'\n",
    "\n",
    "    def __init__(self, ptype='depute', legislature=None):\n",
    "        \"\"\"\n",
    "        type: depute or senateur\n",
    "        legislature: 2007-2012 or None\n",
    "        \"\"\"\n",
    "\n",
    "        assert(ptype in ['depute', 'senateur'])\n",
    "        assert(legislature in ['2007-2012', '2012-2017', None])\n",
    "        self.legislature = legislature\n",
    "        self.ptype = ptype\n",
    "        self.ptype_plural = ptype + 's'\n",
    "        self.base_url = 'https://%s.nos%s.fr' % (legislature or 'www', self.ptype_plural)\n",
    "\n",
    "    def synthese(self, month=None):\n",
    "        \"\"\"\n",
    "        month format: YYYYMM\n",
    "        \"\"\"\n",
    "        if month is None and self.legislature == '2012-2017':\n",
    "            raise AssertionError('Global Synthesis on legislature does not work, see https://github.com/regardscitoyens/nosdeputes.fr/issues/69')\n",
    "\n",
    "        if month is None:\n",
    "            month = 'data'\n",
    "\n",
    "        url = '%s/synthese/%s/%s' % (self.base_url, month, self.format)\n",
    "\n",
    "        data = requests.get(url).json()\n",
    "        return [depute[self.ptype] for depute in data[self.ptype_plural]]\n",
    "\n",
    "    def parlementaire(self, slug_name):\n",
    "        url = '%s/%s/%s' % (self.base_url, slug_name, self.format)\n",
    "        return requests.get(url).json()[self.ptype]\n",
    "\n",
    "    def picture(self, slug_name, pixels='60'):\n",
    "        return requests.get(self.picture_url(slug_name, pixels=pixels))\n",
    "\n",
    "    def picture_url(self, slug_name, pixels='60'):\n",
    "        return '%s/%s/photo/%s/%s' % (self.base_url, self.ptype, slug_name, pixels)\n",
    "\n",
    "    def search(self, q, page=1):\n",
    "        # XXX : the response with json format is not a valid json :'(\n",
    "        # Temporary return csv raw data\n",
    "        url = '%s/recherche/%s?page=%s&format=%s' % (self.base_url, q, page, 'csv')\n",
    "        return requests.get(url).content\n",
    "    \n",
    "    \n",
    "    @memoize\n",
    "    def parlementaires(self, active=None):\n",
    "        if active is None:\n",
    "            url = '%s/%s/%s' % (self.base_url, self.ptype_plural, self.format)\n",
    "        else:\n",
    "            url = '%s/%s/enmandat/%s' % (self.base_url, self.ptype_plural, self.format)\n",
    "\n",
    "        data = requests.get(url).json()\n",
    "        return [depute[self.ptype] for depute in data[self.ptype_plural]]\n",
    "    \n",
    "    def search_parlementaires(self, q, field='nom', limit=5):\n",
    "        return extractBests(q, self.parlementaires(), processor=lambda x: x[field] if type(x) == dict else x, limit=limit)\n",
    "\n",
    "\n",
    "\n",
    "    def interventions(self, dep_name, n_sessions=10, start=4850):\n",
    "        name = self.search_parlementaires(dep_name)[0][0][\"nom\"]\n",
    "        dep_intervention = []\n",
    "        pattern = \"(?<=Permalien\" + name + \")\" + \".*?(?=Voir tous les commentaires)\"\n",
    "        for num_txt in range(start, start + n_sessions):\n",
    "            url = \"https://www.nosdeputes.fr/15/seance/%s\" % (str(num_txt))\n",
    "            source = request.urlopen(url).read()            \n",
    "            # source.encoding = source.apparent_encoding\n",
    "            page = bs4.BeautifulSoup(source, \"lxml\")\n",
    "            x = re.findall(pattern, page.get_text(), flags=re.S)\n",
    "            dep_intervention += x\n",
    "\n",
    "        return dep_intervention\n",
    "    \n",
    "    def interventions2(self, dep_name):\n",
    "        name = self.search_parlementaires(dep_name)[0][0][\"nom\"]\n",
    "        name_pattern = re.sub(' ', '+', unidecode.unidecode(name.lower()))\n",
    "        dep_intervention = []\n",
    "        url = \"https://www.nosdeputes.fr/recherche?object_name=Intervention&tag=parlementaire%3D{0}&sort=1\".format(name_pattern)\n",
    "        source = request.urlopen(url).read()            \n",
    "        page = bs4.BeautifulSoup(source, \"lxml\")\n",
    "        for x in page.find_all('p', {'class' : 'content'}):\n",
    "            dep_intervention += x\n",
    "\n",
    "        return dep_intervention\n",
    "    \n",
    "    def liste_mots(self, dep_name):\n",
    "        name = self.search_parlementaires(dep_name)[0][0][\"nom\"]\n",
    "        name_pattern = re.sub(' ', '-', unidecode.unidecode(name.lower()))\n",
    "        mots_dep = []\n",
    "        url = \"https://www.nosdeputes.fr/{0}/tags\".format(name_pattern)\n",
    "        source = request.urlopen(url).read()            \n",
    "        page = bs4.BeautifulSoup(source, \"lxml\")\n",
    "        for x in page.find_all('span', {'class' : 'tag_level_4'}):\n",
    "            mots_dep.append(re.sub(\"\\n\", \"\", x.get_text()))\n",
    "            \n",
    "        return mots_dep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGU4ALalPCVS"
   },
   "source": [
    "Ensuite, nous avons créé plusieurs DataFrames à l'aide de la fonction interventions 2, avec les fonctions suivantes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eJlvLIZsPCVT"
   },
   "outputs": [],
   "source": [
    "# Fonctions intermédiaires\n",
    "\n",
    "def deputies_of_group(group, n_deputies):\n",
    "    all_names = deputies_df[deputies_df[\"groupe_sigle\"] == group][\"nom\"]\n",
    "    return all_names[:n_deputies]\n",
    "\n",
    "\n",
    "def interventions_of_group(group, n_deputies=15):\n",
    "    names = deputies_of_group(group, n_deputies)\n",
    "    print(names)\n",
    "    interventions = []\n",
    "    for name in names:\n",
    "        print(name)\n",
    "        interventions += [[group, name, api.interventions2(name)]]\n",
    "    return interventions\n",
    "\n",
    "# Fonction de stockage des interventions \n",
    "\n",
    "def stockintervention(groupe):\n",
    "    interventions_group = []\n",
    "    nbdep = deputies_df.groupby('groupe_sigle')['nom'].count()[str(groupe)]\n",
    "    print(nbdep)\n",
    "    interventions_group += interventions_of_group(groupe, nbdep)\n",
    "    interventions_df = pd.DataFrame(\n",
    "        interventions_group,\n",
    "        columns=[\"groupe\", \"nom\", \"interventions\"]\n",
    "        )\n",
    "    \n",
    "    return interventions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwHj_lLqPCVT"
   },
   "source": [
    "Voici un exemple d'utilisation. Pour éviter de perdre du temps ici (la fonction peut mettre du temps à s'exécuter sur les échantillons de grande taille), on exécute la fonction sur un petit parti politique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hI2VdK4aPCVU",
    "outputId": "090c474b-ea59-44e4-b677-d10b5c4030c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "76           Yves Jégo\n",
      "80      Franck Riester\n",
      "289      Maurice Leroy\n",
      "515    Napole Polutele\n",
      "Name: nom, dtype: object\n",
      "Yves Jégo\n",
      "Franck Riester\n",
      "Maurice Leroy\n",
      "Napole Polutele\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>groupe</th>\n",
       "      <th>nom</th>\n",
       "      <th>interventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UAI</td>\n",
       "      <td>Yves Jégo</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UAI</td>\n",
       "      <td>Franck Riester</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UAI</td>\n",
       "      <td>Maurice Leroy</td>\n",
       "      <td>[Maurice Leroy  – Nous avons examiné la PPE en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UAI</td>\n",
       "      <td>Napole Polutele</td>\n",
       "      <td>[ Oui, madame la présidente. ,  Madame la mini...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  groupe              nom                                      interventions\n",
       "0    UAI        Yves Jégo                                                 []\n",
       "1    UAI   Franck Riester                                                 []\n",
       "2    UAI    Maurice Leroy  [Maurice Leroy  – Nous avons examiné la PPE en...\n",
       "3    UAI  Napole Polutele  [ Oui, madame la présidente. ,  Madame la mini..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = CPCApi()\n",
    "deputies_json = api.parlementaires()\n",
    "deputies_df = pd.json_normalize(deputies_json)\n",
    "\n",
    "UAI_df = stockintervention('UAI')\n",
    "UAI_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAInatZOPCVV"
   },
   "source": [
    "Importons maintenant les données qui nous intéressent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kT8sAhwMPCVW"
   },
   "outputs": [],
   "source": [
    "LFI_df = pd.read_csv(\"https://raw.githubusercontent.com/rturquier/depythons/main/Stock_csv/LFI2_inter.csv\")\n",
    "LREM_df = pd.read_csv(\"https://raw.githubusercontent.com/rturquier/depythons/main/Stock_csv/LREM2_inter.csv\")\n",
    "LR_df = pd.read_csv(\"https://raw.githubusercontent.com/rturquier/depythons/main/Stock_csv/LR2_inter.csv\")\n",
    "SOC_df = pd.read_csv(\"https://raw.githubusercontent.com/rturquier/depythons/main/Stock_csv/SOC2_inter.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xM3XXd3KlFz0"
   },
   "source": [
    "## Nettoyage des données\n",
    "Après une exploration préliminaire, nous avons choisi de nous concentrer sur deux groupes parlementaires. Les groupes LFI et LR nous ont paru ceux les plus susceptibles d'utiliser un discours différent et que nous pourrions distinguer dans notre modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "im9QOPF57LlX"
   },
   "outputs": [],
   "source": [
    "### Import des données brutes récupérées avec l'API\n",
    "data_url = \"https://raw.githubusercontent.com/rturquier/depythons/main/Stock_csv/gd2_inter.csv\"\n",
    "df_brut = pd.read_csv(data_url)\n",
    "df_brut.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "KhTIgGQn73gU",
    "outputId": "4ab419d5-647e-44a7-e67d-e2b8ea0d9002"
   },
   "outputs": [],
   "source": [
    "# Création d'une indicatrice `droite` qui sera la cible de la classification\n",
    "df_brut = df_brut.assign(droite = df_brut[\"groupe\"] == \"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6SDD_yytQU6",
    "outputId": "abdc0eaa-4501-48f7-c6c2-d3dcea900fed"
   },
   "outputs": [],
   "source": [
    "# Équilibrage du nombre de députés\n",
    "def balance_left_right(df):\n",
    "  count = df.droite.value_counts()\n",
    "  n_droite, n_gauche = count[True], count[False]\n",
    "  df = df.sort_values(by = [\"droite\"], ascending = False)\n",
    "  \n",
    "  if n_droite > n_gauche :\n",
    "    df = df[n_droite - n_gauche:]\n",
    "  elif n_droite < n_gauche :\n",
    "    df = df[2 * n_droite:]\n",
    "\n",
    "  return df\n",
    "\n",
    "df_brut = balance_left_right(df_brut)\n",
    "df_brut.droite.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "O0lFEGtugn2k",
    "outputId": "1514b6d3-6d2c-4796-c7d1-ba2c2e4122b9"
   },
   "outputs": [],
   "source": [
    "# Régler un problème de type\n",
    "from ast import literal_eval\n",
    "def convert_to_list(interventions):\n",
    "  return literal_eval(str(interventions))\n",
    "\n",
    "df_brut[\"interventions\"] = df_brut[\"interventions\"].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0wHQO2L-MBX"
   },
   "outputs": [],
   "source": [
    "# Séparer toutes les interventions en colonnes différentes\n",
    "df_tidy = df_brut.explode(\"interventions\")\n",
    "df_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "2byMHZf7ZDsj",
    "outputId": "14293485-2624-4066-f5d8-66c6862b41c4"
   },
   "outputs": [],
   "source": [
    "# Créer une feature \"longeur de l'intervention\"\n",
    "df_brut = df_brut.assign(longeur = df_brut[\"interventions\"].str.len())\n",
    "df_brut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EX1okKFfQcNn"
   },
   "source": [
    "## Exploration et feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tr7evwW0QdVy"
   },
   "outputs": [],
   "source": [
    "# Il faudrait faire un test-train-split ici, je crois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Yjhplu3QhBp"
   },
   "outputs": [],
   "source": [
    "# Création de features simples : \n",
    "# - longueur de l'intervention, en nombre de caractères\n",
    "# - nombre de points d'exclamation\n",
    "# - nombre de points d'interrogation\n",
    "df_tidy = df_tidy.assign(\n",
    "    longueur = df_tidy[\"interventions\"].str.len(),\n",
    "    exclamation = df_tidy[\"interventions\"].str.count(\"!\"),\n",
    "    interrogation = df_tidy[\"interventions\"].str.count(\"\\?\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0ZAydeEPCVc"
   },
   "source": [
    "## Visualisation des données (wordcloud, statistiques descriptives...)\n",
    "\n",
    "Nous allons maintenant dans cette partie visualiser les tendances dans les différents partis, ainsi que les mots qui sont les plus utilisés. Nous commençons par le wordcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhEb0zObPCVd"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from urllib import request\n",
    "\n",
    "# Création d'un stopwords\n",
    "\n",
    "stopping_list = request.urlopen(\"https://raw.githubusercontent.com/rturquier/depythons/main/stopwords-fr.txt\").read()\n",
    "stopping_list = stopping_list.decode('utf-8')\n",
    "stopwords_list = stopping_list.split('\\n')\n",
    "\n",
    "def wordcloud_gen(dep_name):\n",
    "    name = api.search_parlementaires(dep_name)[0][0]['nom']\n",
    "    text_dep = api.interventions2(name)\n",
    "    \n",
    "    text_cloud = \"\"\n",
    "    for morceau in text_dep:\n",
    "        text_cloud += morceau\n",
    "    \n",
    "    stopwords = set(STOPWORDS)  \n",
    "    stopwords.update(stopwords_list)\n",
    "\n",
    "    try_cloud = WordCloud(stopwords = stopwords,\n",
    "                          max_font_size=50, max_words=150, \n",
    "                          background_color=\"white\").generate(text_cloud)\n",
    "\n",
    "    plt.imshow(try_cloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esjyOFUXPCVe"
   },
   "source": [
    "Quelques petits essais..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OU4eFFXUPCVe",
    "outputId": "ab16e9fe-7214-45f6-e213-407f17829ccd"
   },
   "outputs": [],
   "source": [
    "wordcloud_gen(\"Jean-Luc Mélenchon\"), wordcloud_gen('Eric Ciotti')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-RmXt3xPCVf"
   },
   "source": [
    "### Liste de mots customisée\n",
    "\n",
    "Créons dès à présent une fonction qui retourne les mots les plus utilisés par les membres d'un parti. Cette liste de mots va nous servir pour modéliser les champs lexicaux (quel parti a le plus tendance à utiliser tel mot ?). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xkllno7mPCVg"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def give_text(groupe_df):\n",
    "    list_groupe = []\n",
    "    for words in groupe_df['interventions']:\n",
    "        list_groupe.append(words)\n",
    "        \n",
    "    text_groupe = \"\"\n",
    "    \n",
    "    for block in list_groupe:\n",
    "        for carac in block:\n",
    "            text_groupe += carac\n",
    "            \n",
    "    return text_groupe\n",
    "\n",
    "\n",
    "\n",
    "def customized(parti_df, nb_mots=100):\n",
    "    parti_split = give_text(parti_df).split()\n",
    "    parti_pure = [word for word in parti_split if word not in stopwords_list]\n",
    "    parti_counter = Counter(parti_pure)\n",
    "    parti_commons = parti_counter.most_common(nb_mots)\n",
    "    \n",
    "    customized_list = []\n",
    "    for x in parti_commons:\n",
    "        customized_list.append(x[0])\n",
    "    \n",
    "    return customized_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1jlrJsUPCVh"
   },
   "source": [
    "Utilisons ces fonctions pour créer une liste de mots customisée, qui contient les mots les plus utilisés, partis de gauche et de droite confondus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0lSH6JWPCVh",
    "outputId": "a243f78a-7908-4342-b754-89bfd768da17"
   },
   "outputs": [],
   "source": [
    "super_liste = customized(LFI_df) + customized(LR_df) + customized(SOC_df)\n",
    "super_liste = list(set(super_liste)) # Suppression des doublons\n",
    "super_liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xpEE2y5JPCVi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Rendu.ipynb",
   "provenance": []
  },
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "depythons",
   "language": "python",
   "name": "depythons"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
